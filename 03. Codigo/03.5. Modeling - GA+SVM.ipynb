{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BankruptcyProject.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.8.6 64-bit"},"language_info":{"name":"python","version":"3.8.6"},"interpreter":{"hash":"a6974f591a6cacf7a81ec2d11a96a55a57f0f00ff64e51bda44c50474fd6653c"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eJ0hxe84psVf"},"source":["## Importacion de librerias"]},{"cell_type":"code","metadata":{"id":"9ecVSwJDWhU9","executionInfo":{"status":"ok","timestamp":1622828394535,"user_tz":300,"elapsed":707,"user":{"displayName":"Luis Miguel Enciso Salas","photoUrl":"","userId":"02884223281026621413"}}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import KFold\n","from scipy.io import arff\n","import random\n","from collections import OrderedDict\n","import seaborn as sns\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","\n","from deap import base, creator, tools, algorithms\n","from sklearn.base import clone, is_classifier\n","\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import StratifiedKFold\n","\n","# sklearn-optimize es tomado de: https://github.com/senolakkas/sklearn-optimize\n","from sklearn_genetic.genetic import GeneticSearchCV\n","\n","import joblib\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","from sklearn.metrics import confusion_matrix\n","from tabulate import tabulate\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\lmes_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n  warnings.warn(message, FutureWarning)\n"]}]},{"cell_type":"markdown","metadata":{"id":"JUGqjhlkpvmI"},"source":["## Leer dataset imputado"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["median_imputed_df = pd.read_pickle(os.path.join('results','median_imputed_data.pkl'))"]},{"cell_type":"code","metadata":{"id":"Ni_j9Az_7hcT","executionInfo":{"status":"ok","timestamp":1622828439547,"user_tz":300,"elapsed":41,"user":{"displayName":"Luis Miguel Enciso Salas","photoUrl":"","userId":"02884223281026621413"}}},"source":["# Splitting features and labels\n","def split_features_labels(df):\n","    feature_dfs = df.iloc[:, 1:]\n","    label_dfs = df['flag']\n","    return feature_dfs, label_dfs"],"execution_count":3,"outputs":[]},{"source":["## Estrategia de validacion"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# K-Fold Cross Validation\n","def kfold_cv(k, X, y, verbose=False):\n","    X = X.values  # Features\n","    y = y.values  # Labels\n","    kf = KFold(n_splits=k, shuffle=False, random_state=42)\n","    X_train = []\n","    y_train = []\n","    X_test = []\n","    y_test = []\n","\n","    for train_index, test_index in kf.split(X):\n","        X_train.append(X[train_index])\n","        y_train.append(y[train_index])\n","        X_test.append(X[test_index])\n","        y_test.append(y[test_index])\n","    return X_train, y_train, X_test, y_test\n","seed = 7"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# perform data modeling using a dict of models\n","def perform_data_modeling(_models_, imputed_df, verbose=False, k_folds=5):\n","    # 7 metrics, averaged over all the K-Folds\n","    model_results = OrderedDict()\n","\n","    # Iterate over classifiers\n","    for model_name, clf in _models_.items():\n","        if verbose: print(\"-\" * 120, \"\\n\", \"Model: \" + '\\033[1m' + model_name + '\\033[0m' + \" Classifier\")\n","        imputer_results = OrderedDict()\n","\n","        # Mean imputation is in a dictionary and iterating over that.In our case, only mean_imputation is implemented\n","        features_df, labels_df = split_features_labels(imputed_df)\n","\n","        years = OrderedDict()\n","        df_index = 0\n","        if verbose: print('\\t\\tDataset: ' + '\\033[1m' + str(df_index + 1) + 'year' + '\\033[0m')\n","        # Running K-fold cross validation on train and test set\n","        X_train_list, y_train_list, X_test_list, y_test_list = kfold_cv(k_folds, features_df,\n","                                                                        labels_df, verbose)\n","\n","        metrics = OrderedDict()\n","\n","        # Calculating accuracy, precision, recall, and confusion matrix\n","        # Initializing these variables with a numpy array of 0\n","\n","        accuracy_list = np.zeros([k_folds])\n","        precision_list = np.zeros([k_folds, 2])\n","        recall_list = np.zeros([k_folds, 2])\n","        true_negs = np.zeros([k_folds])\n","        false_pos = np.zeros([k_folds])\n","        false_negs = np.zeros([k_folds])\n","        true_pos = np.zeros([k_folds])\n","\n","        # Iterate over all the k-folds and calculate accuracy, precision and confusion matrix\n","        for k in range(k_folds):\n","            X_train = X_train_list[k]\n","            y_train = y_train_list[k]\n","            X_test = X_test_list[k]\n","            y_test = y_test_list[k]\n","\n","            # Fit the model and call predict function for test set\n","            clf = clf.fit(X_train, y_train)\n","\n","            y_test_predicted = clf.predict(X_test)\n","            print(confusion_matrix(y_test_predicted, y_test))\n","\n","            _accuracy_ = accuracy_score(y_test, y_test_predicted, normalize=True)\n","            accuracy_list[k] = _accuracy_\n","            _recalls_ = recall_score(y_test, y_test_predicted, average=None)\n","            recall_list[k] = _recalls_\n","\n","            # code for calculating precision\n","            _precisions_ = precision_score(y_test, y_test_predicted, average=None)\n","            precision_list[k] = _precisions_\n","\n","            # code for calculating confusion matrix\n","            _confusion_matrix_ = confusion_matrix(y_test, y_test_predicted)\n","            mlp_cm = confusion_matrix(y_test, y_test_predicted)\n","\n","            true_negs[k] = _confusion_matrix_[0][0]\n","            false_pos[k] = _confusion_matrix_[0][1]\n","            false_negs[k] = _confusion_matrix_[1][0]\n","            true_pos[k] = _confusion_matrix_[1][1]\n","\n","        metrics['Accuracy'] = np.mean(accuracy_list)\n","        metrics['Precisions'] = np.mean(precision_list, axis=0)\n","        metrics['Recalls'] = np.mean(recall_list, axis=0)\n","        metrics['TN'] = np.mean(true_negs)\n","        metrics['FP'] = np.mean(false_pos)\n","        metrics['FN'] = np.mean(false_negs)\n","        metrics['TP'] = np.mean(true_pos)\n","\n","        if verbose:\n","            print('\\t\\t\\tAccuracy:', metrics['Accuracy'])\n","            print('\\t\\t\\tPrecision:', metrics['Precisions'])\n","            print('\\t\\t\\tRecall:', metrics['Recalls'])\n","\n","        model_results[model_name] = metrics\n","\n","    sns.heatmap(mlp_cm, annot=True,\n","                xticklabels=['Non Bankrupt', 'Bankrupt'],\n","                yticklabels=['Non Bankrupt', 'Bankrupt'])\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.show()\n","\n","    return model_results\n","\n","\n","# perform ranking by metrics\n","def perform_model_ranking_acc(models, imputers, results):\n","    column_headers = ['-','Accuracy'] \n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        row.append(model_details['Accuracy'])\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df\n","\n","def perform_model_ranking_prec(models, imputers, results):\n","    column_headers = ['-','Precisions']\n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        row.append(model_details['Precisions'])\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df\n","\n","def perform_model_ranking_rec(models, imputers, results):\n","    column_headers = ['-','Recalls']\n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        row.append(model_details['Recalls'])\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df\n","\n","def perform_model_ranking_tn(models, imputers, results):\n","    column_headers = ['-','TN']\n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        row.append(model_details['TN'])\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df\n","\n","def perform_model_ranking_fp(models, imputers, results):\n","    column_headers = ['-','FP']\n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        row.append(model_details['FP'])\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df\n","\n","def perform_model_ranking_fn(models, imputers, results):\n","    column_headers = ['-','FN']\n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        row.append(model_details['FN'])\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df\n","\n","def perform_model_ranking_tp(models, imputers, results):\n","    column_headers = ['-','FP']\n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        row.append(model_details['TP'])\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["param = {'kernel': ['rbf'],\n","          'C': [0, 100], \n","          'gamma': [0.01, 0.001]}\n","param_ga = {\"kernel\": [\"rbf\", \"sigmoid\", \"linear\"],\n","             \"C\": np.logspace(-9, 9, num=25, base=10),\n","             \"gamma\": np.logspace(-9, 9, num=25, base=10)}"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["X, y = split_features_labels(median_imputed_df)"]},{"source":["**Don't want to wait?, put load to 1!**"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["load = 1"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# svm simple search\n","cv_svm = GridSearchCV(estimator=SVC(), \n","                      param_grid=param,\n","                      scoring=\"accuracy\",\n","                      cv=5)\n","if load==0:\n","  cv_svm.fit(X, y)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# GeneticSearchCV modified\n","class GeneticSearchCVMod(GeneticSearchCV):\n","     def __init__(self, estimator, params, scoring=None, cv=4,\n","                 refit=True, verbose=False, population_size=50,\n","                 gene_mutation_prob=0.1, gene_crossover_prob=0.5,\n","                 tournament_size=3, generations_number=10, gene_type=None,\n","                 n_jobs=1, iid=True, error_score='raise',\n","                 fit_params={}):\n","        super(GeneticSearchCV, self).__init__(\n","            estimator=estimator, scoring=scoring,\n","            iid=iid, refit=refit, cv=cv, verbose=verbose,\n","            error_score=error_score)\n","        self.fit_params=fit_params\n","        self.params = params\n","        self.population_size = population_size\n","        self.generations_number = generations_number\n","        self._individual_evals = {}\n","        self.gene_mutation_prob = gene_mutation_prob\n","        self.gene_crossover_prob = gene_crossover_prob\n","        self.tournament_size = tournament_size\n","        self.gene_type = gene_type\n","        self.all_history_, self.all_logbooks_ = [], []\n","        self._cv_results = None\n","        self.best_score_ = None\n","        self.best_params_ = None\n","        self.score_cache = {}\n","        self.n_jobs = n_jobs\n","        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","        creator.create(\"Individual\", list, est=clone(self.estimator), fitness=creator.FitnessMax)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# svm + ga\n","cv_svm_ga = GeneticSearchCVMod(estimator=SVC(),\n","                     params=param_ga,\n","                     scoring=\"accuracy\",\n","                     cv=StratifiedKFold(n_splits=4),\n","                     verbose=1,\n","                     population_size=50,\n","                     gene_mutation_prob=0.10,\n","                     gene_crossover_prob=0.5,\n","                     tournament_size=3,\n","                     generations_number=5,\n","                     n_jobs=4)\n","if load == 0:\n","  cv_svm_ga.fit(X, y)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# save grid-searchs\n","if load == 0:\n","  joblib.dump(cv_svm, os.path.join('modelos','Modelo_SVM.pkl'))\n","  joblib.dump(cv_svm_ga, os.path.join('modelos','Modelo_GA_SVM.pkl'))"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["if load:\n","  cv_svm = joblib.load(os.path.join('modelos','Modelo_SVM.pkl'))\n","  cs_svm_ga = joblib.load(os.path.join('modelos','Modelo_GA_SVM.pkl'))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'GeneticSearchCVMod' object has no attribute 'best_estimator_'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m<ipython-input-17-0d3b4fd49183>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msvm_ga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_svm_ga\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodels_dictionary2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodels_dictionary2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SVM'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodels_dictionary2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SVM+GA'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_ga\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mAttributeError\u001b[0m: 'GeneticSearchCVMod' object has no attribute 'best_estimator_'"]}],"source":["svm = cv_svm.best_estimator_\n","svm_ga = cv_svm_ga.\n","models_dictionary2 = OrderedDict()\n","models_dictionary2['SVM'] = svm\n","models_dictionary2['SVM+GA'] = svm_ga"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ideally 5 fold cross validation yielded better results\n","results2 = perform_data_modeling(models_dictionary2, mean_imputed_df, verbose=True, k_folds=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(perform_model_ranking_acc(models_dictionary2, imputed_dict, results2))\n","print(perform_model_ranking_prec(models_dictionary2, imputed_dict, results2))\n","print(perform_model_ranking_rec(models_dictionary2, imputed_dict, results2))\n","print(perform_model_ranking_tn(models_dictionary2, imputed_dict, results2))\n","print(perform_model_ranking_fp(models_dictionary2, imputed_dict, results2))\n","print(perform_model_ranking_fn(models_dictionary2, imputed_dict, results2))\n","print(perform_model_ranking_tp(models_dictionary2, imputed_dict, results2))"]}]}