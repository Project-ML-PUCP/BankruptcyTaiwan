{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BankruptcyProject.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.8.6 64-bit"},"language_info":{"name":"python","version":"3.8.6"},"interpreter":{"hash":"a6974f591a6cacf7a81ec2d11a96a55a57f0f00ff64e51bda44c50474fd6653c"}},"cells":[{"cell_type":"markdown","metadata":{"id":"M4gLpuREplp7"},"source":["## Importación de librerías"]},{"cell_type":"code","metadata":{"id":"9ecVSwJDWhU9","executionInfo":{"status":"ok","timestamp":1622828394535,"user_tz":300,"elapsed":707,"user":{"displayName":"Luis Miguel Enciso Salas","photoUrl":"","userId":"02884223281026621413"}}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import KFold\n","from scipy.io import arff\n","import random\n","from collections import OrderedDict\n","import seaborn as sns\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","from sklearn.metrics import confusion_matrix\n","## sklearn-optimize es tomado de: https://github.com/senolakkas/sklearn-optimize\n","from sklearn_genetic.genetic import GeneticSearchCV\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","import joblib\n","from sklearn.metrics import roc_curve, roc_auc_score\n","from tabulate import tabulate\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# GeneticSearchCV modificado\n","class GeneticSearchCVMod(GeneticSearchCV):\n","     def __init__(self, estimator, params, scoring=None, cv=4,\n","                 refit=True, verbose=False, population_size=50,\n","                 gene_mutation_prob=0.1, gene_crossover_prob=0.5,\n","                 tournament_size=3, generations_number=10, gene_type=None,\n","                 n_jobs=1, iid=True, error_score='raise',\n","                 fit_params={}):\n","        super(GeneticSearchCV, self).__init__(\n","            estimator=estimator, scoring=scoring,\n","            iid=iid, refit=refit, cv=cv, verbose=verbose,\n","            error_score=error_score)\n","        self.fit_params=fit_params\n","        self.params = params\n","        self.population_size = population_size\n","        self.generations_number = generations_number\n","        self._individual_evals = {}\n","        self.gene_mutation_prob = gene_mutation_prob\n","        self.gene_crossover_prob = gene_crossover_prob\n","        self.tournament_size = tournament_size\n","        self.gene_type = gene_type\n","        self.all_history_, self.all_logbooks_ = [], []\n","        self._cv_results = None\n","        self.best_score_ = None\n","        self.best_params_ = None\n","        self.score_cache = {}\n","        self.n_jobs = n_jobs\n","        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","        creator.create(\"Individual\", list, est=clone(self.estimator), fitness=creator.FitnessMax)"]},{"cell_type":"markdown","metadata":{"id":"JUGqjhlkpvmI"},"source":["## Lectura de modelos guardados"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# cargamos los modelos\n","dt_model = joblib.load(os.path.join('modelos','Modelo_DT.pkl'))\n","#lr_model = joblib.load(os.path.join('modelos','Modelo_LR.pkl'))\n","rf_model = joblib.load(os.path.join('modelos','Modelo_RF.pkl'))\n","xgb_model = joblib.load(os.path.join('modelos','Modelo_XGB.pkl'))\n","cv_svm_model = joblib.load(os.path.join('modelos','Modelo_SVM.pkl'))\n","#cs_svm_ga_model = joblib.load(os.path.join('modelos','Modelo_GA_SVM.pkl'))"]},{"source":["## Lectura de dataset imputado"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# se carga dataset imputado\n","median_imputed_df = pd.read_pickle(os.path.join('results','dataset_normalizado.pkl'))"]},{"cell_type":"markdown","metadata":{"id":"qVID3kM9p3mO"},"source":["## Evaluación de modelos"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Modelamiento de la data usando un diccionario de datasets y modelos\n","def perform_data_modeling(_models_, imputed_df, verbose=False, k_folds=5):\n","    # 7 metricas, usando K-Folds\n","    # en model_results guardaremos los resultados por clasificador y datasets\n","    model_results = OrderedDict()\n","\n","    # Iteramos sobre los clasificadores\n","    for model_name, clf in _models_.items():\n","        if verbose: print(\"-\" * 120, \"\\n\", \"Model: \" + '\\033[1m' + model_name + '\\033[0m' + \" Classifier\")\n","        imputer_results = OrderedDict()\n","\n","        # hacemos la division del dataframe en variables y etiquetas\n","        features_df, labels_df = split_features_labels(imputed_df)\n","\n","        df_index = 0\n","        if verbose: print('\\t\\tDataset: ' + '\\033[1m' + str(df_index + 1) + 'year' + '\\033[0m')\n","        # Ejecutamos la validación cruzada K-fold en los sets de entranamiento y test\n","        X_train_list, y_train_list, X_test_list, y_test_list = kfold_cv(k_folds, features_df, labels_df, verbose)\n","\n","        metrics = OrderedDict()\n","\n","        # incializamos las metricas a guardar\n","        accuracy_list = np.zeros([k_folds])\n","        precision_list = np.zeros([k_folds, 2])\n","        recall_list = np.zeros([k_folds, 2])\n","        true_negs = np.zeros([k_folds])\n","        false_pos = np.zeros([k_folds])\n","        false_negs = np.zeros([k_folds])\n","        true_pos = np.zeros([k_folds])\n","        auc_list = np.zeros([k_folds])\n","\n","        # Iteramos sobre los k-folds para el cálculo de las métricas\n","        for k in range(k_folds):\n","            X_train = X_train_list[k]\n","            y_train = y_train_list[k]\n","            X_test = X_test_list[k]\n","            y_test = y_test_list[k]\n","\n","            # y predicción en el set de test\n","            y_test_predicted = clf.predict(X_test)\n","            # presentamos la matriz de confusión\n","            print(confusion_matrix(y_test_predicted, y_test))\n","\n","            # guardamos accuracy y recall\n","            _accuracy_ = accuracy_score(y_test, y_test_predicted, normalize=True)\n","            accuracy_list[k] = _accuracy_\n","            _recalls_ = recall_score(y_test, y_test_predicted, average=None)\n","            recall_list[k] = _recalls_\n","\n","            # guardamos precision\n","            _precisions_ = precision_score(y_test, y_test_predicted, average=None)\n","            precision_list[k] = _precisions_\n","\n","            # calculamos la matriz de confusión\n","            _confusion_matrix_ = confusion_matrix(y_test, y_test_predicted)\n","            mlp_cm = confusion_matrix(y_test, y_test_predicted)\n","\n","            # guardamos demás valores: TN, FP, FN, TP\n","            true_negs[k] = _confusion_matrix_[0][0]\n","            false_pos[k] = _confusion_matrix_[0][1]\n","            false_negs[k] = _confusion_matrix_[1][0]\n","            true_pos[k] = _confusion_matrix_[1][1]\n","\n","            # calculamos el auc\n","            _auc_curve_ = roc_auc_score(y_test, y_test_predicted)\n","            # guardamos auc\n","            auc_list[k] = _auc_curve_\n","\n","        # Hacemos la media en el caso de más datasets\n","        metrics['Accuracy'] = np.mean(accuracy_list)\n","        metrics['Precisions'] = np.mean(precision_list, axis=0)\n","        metrics['Recalls'] = np.mean(recall_list, axis=0)\n","        metrics['TN'] = np.mean(true_negs)\n","        metrics['FP'] = np.mean(false_pos)\n","        metrics['FN'] = np.mean(false_negs)\n","        metrics['TP'] = np.mean(true_pos)\n","        metrics['AUC'] = np.mean(auc_list)\n","\n","        # presentamos algunos valores\n","        if verbose:\n","            print('\\t\\t\\tAccuracy:', metrics['Accuracy'])\n","            print('\\t\\t\\tRecall:', metrics['Recalls'])\n","\n","        # guardamos en el diccionario\n","        model_results[model_name] = metrics\n","\n","    # presentamos la matriz de confusión en modo mapa de calor\n","    sns.heatmap(mlp_cm, annot=True,\n","                xticklabels=['Non Bankrupt', 'Bankrupt'],\n","                yticklabels=['Non Bankrupt', 'Bankrupt'])\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.show()\n","\n","    return model_results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Hacer ranking por cada métrica\n","def perform_model_ranking_acc(models, imputers, results):\n","    column_headers = ['-','Accuracy'] \n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        row.append(model_details['Accuracy'])\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df\n","\n","def perform_model_ranking_f1score(models, imputers, results):\n","    column_headers = ['-','F1-score']\n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        recall = model_details['Recalls']\n","        precision = model_details['Precisions']\n","        f1score = 2*(recall*precision)/(recall+precision)\n","        row.append(f1score)\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df\n","\n","def perform_model_ranking_auc(models, imputers, results):\n","    column_headers = ['-','AUC']\n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        row.append(model_details['AUC'])\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df\n","\n","def perform_model_ranking_typeI(models, imputers, results):\n","    column_headers = ['-','FP']\n","    rows = []\n","    for model_name, model_details in results.items():\n","        row = [model_name]\n","        row.append(model_details['FP'])\n","        rows.append(row)\n","    results_df = pd.DataFrame(data=rows, columns = column_headers)\n","    return results_df"]},{"source":["## Análisis comparativo"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# models\n","svm = cv_svm_model.best_estimator_\n","models_dictionary2 = OrderedDict()\n","models_dictionary2['SVM'] = svm\n","models_dictionary2['SVM+GA'] = svm_ga\n","models_dictionary2['DT'] = svm"]},{"source":["**Comparación**"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"source":["**Tablas**"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"source":["## Prducción de gráficos"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}